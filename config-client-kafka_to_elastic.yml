#config file for KafkaConsumerConfig class
server:
  port: 8182

kafka-config:
  bootstrap-servers: localhost:19092, localhost:29092, localhost:39092
  schema-registry-url-key: schema.registry.url
  schema-registry-url: http://localhost:8081
  topic-name: twitter-topic
  topic-names-to-create:
    - twitter-topic

kafka-consumer-config:
  key-deserializer: org.apache.kafka.common.serialization.LongDeserializer
  value-deserializer: io.confluent.kafka.serializers.KafkaAvroDeserializer
  consumer-group-id: twitter-topic-consumer # set unique id to consumer to allow using offset
  auto-offset-reset: earliest # we want to start reading beginning of partition
  specific-avro-reader-key: specific.avro.reader
  specific-avro-reader: true
  batch-listener: true # allows to consume data batches
  auto-startup: false # start when topic is available
  concurrency-level: 3 # sets the number of threads to work on consuming, ex : 1 topic, 4 partitions-> set as 4
  session-timeout-ms: 10000
  heartbeat-interval-ms: 3000 # send signal to broker saying I am alive , session timeout usually set to more than 3X heart beat time
  max-poll-interval-ms: 300000 # processing time
  max-poll-records: 500 # max record fetch in each call
  max-partition-fetch-bytes-default: 1048576 # max bytes fetch in each call
  max-partition-fetch-bytes-boost-factor: 1
  poll-timeout-ms: 150 # how long we will wait usually this value around 100 for optimize

retry-config:
  initial-interval-ms: 1000
  max-interval-ms: 10000
  multiplier: 2.0
  maxAttempts: 3
  sleep-time-ms: 2000

elastic-config:
  index-name: twitter-index
  connection-url: http://localhost:9200
  connection-timeout-ms: 5000
  socket-timeout-ms: 30000
  is-repository: true
